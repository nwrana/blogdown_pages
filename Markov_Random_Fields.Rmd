---
title: "Markov Random Fields"
author: "Nathan Wrana"
date: "January 6, 2018"
output: html_document
---

The best way to learn Markov Chains is to breakdown several examples of how they are used:  
1. Markov Chain Monte-carlo for Bayesian Inference - The Metropolis-Hastings and Gibbs Sampling Algorithms  
2. Dynamic Hedge Ratio Between ETF Pairs Using the Kalman Filter  
3. Hidden Markov Models for Regime Detection  
4. Image recognition 
5. Natural Language Processing

## Markov Chain Monte-Carlo for Bayesian Inference

_the following disciption was taken from the following source:
[A simple introduction to Markov Chain Monte-Carlo sampling](https://link.springer.com/article/10.3758/s13423-016-1015-8)_ 

Markov chain Monte-Carlo (MCMC) is a computer driven sampling method. It allows one to characterize a distribution without knowing all of the distribution's mathematical properties by randomly sampling values out of the distribution.  

_insert example here_  

A particular strength of MCMC is that it can be used to draw samples from distributions even when all that is know about the distribution is how to calculate the density for different samples. 

_example: prior distribution and likelihood distribution are known. We would like to know what the posterior distribution. MCMC can generater samples of the posterior by calculating prior x likelihood using different parameters. A histogram can be created fromn ths result and posterior properties like mean, sd, etc can be extracted_  

The name MCMC combins two properties: _Monte-Carlo_ and _Markov chain_. Monte-Carlo is the practice of estimating the properties of a distribution by examining random samples from the distribution. For example, instead of finding the mean of a normal distribution by directly calculating it from the distribution's equation, a Monte-Carlo approach would be to draw a large number of random samples from a normal distribution, and calculate teh sample mean of those. 

_insert the analytical approach of find the mean of a normal distribution thorugh integration AND write a python script that shows how one can sample from this distribution to approxiamte the same thing_  

The benefit of Monte-Carlo approach is clear: calculating the mean of a large sample of numbers can be much easier than calculating the mean directly from the normal distribution's equation. __The benefit is most pronounced when random samples are easy to draw, and when the distribution's equations are hard to work with in other ways.__  

_need to include examples that explain the previous sentence_ 

The Markov chain property of MCMC is the idea that the random samples are generated by a special sequential process. Each random sample is used as a stepping stone to generate the next random sample (hence the _chain_). A special property of the chain is that, while each new sample depends on the one before it, new samples do _not_ depend on any samples before the previous one. This is called the __'Markov Property'__. 

_explain the Markov Property here or reference the explanation that would appear in a section describing what a Markov Field is_  

### Metropolis-Hastings MCMC algorithm  

[A simple Metropolis-Hastings MCMC in R](https://theoreticalecology.wordpress.com/2010/09/17/metropolis-hastings-mcmc-in-r/)  

It is instructive to program a simple MCMC yourself to understand how these algorithms work. We will walk thorugh an example of the Bayesian equivalent of linear regression, sampled ny a MCMC with Metropolis-Hastings steps:  

#### Creating test data  

As a first step, we need to create some test data that we will use to fit our model. We will assume a linear relationship between predictor and response variables, so we take a linear model and add some noise. 

``` {r MCMC_met-hast}

trueA <- 5
trueB <- 0
trueSd <- 10
sampleSize <- 31

# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize- 1)/2)
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)

plot(x,y,main='Test Data')
```  

#### Defining the statistical model 

The next step is to specify the statistical model. we already know the data was created with a linear relationhsip $y=ax + b + \epsilon$. The error is normally distributed with standard deviation, $\mathcal{N}(\mu=0,\,\sigma^{2})$. So lets use the same model and see if we can retrive our original parameter values using MCMC.  

#### Derive the likelihood function from the model 

For estimating parameters in a Bayesian analysis, we need to derive the _likelihood function_ for the model we want to fit. The likelihood is the probability of the observed data given the parameters of the model we're looking at $p(data|\theta)$. So, given our linear model has the following parameters $\theta = (a, b, \sigma^{2})$, we have to return the probability of obtaining the test data created above.  

``` {r likelihood_function}  

likelihood <- function(param){
  a <- param[1]
  b <- param[2]
  sd <- param[3]
  
  prediction <- a*x + b #remember, x is a vector from -15 to 15 in increments of 1; i.e. -15,-14....14,15
  singlelikelihoods <- dnorm(y, mean = prediction, sd = sd, log = TRUE) #return the log of teh densities
  sumll <- sum(singlelikelihoods) #take the sum of the log likelihood
  return(sumll)
}

#Example: plot the likelihood profile of slope a
slopevalues <- function(x) {return(likelihood(c(x, trueB, trueSd)))} #executes the function 'likelihood'
slopelikelihoods <- lapply(seq(3, 7, by=0.05), slopevalues) #applies the function across a sequence of values from 3 to 7 in increments of 0.05
plot(seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")

```  
__Note:__ we return the logarithm of the probabilties in the likelihood function, which is also the reason why we sum the probabilties of our datapoints (i.e the log of a product equals the sum of teh logarithms). We do this because we generate a lot of probabilities that are small. Multiplying these values can generate extremely small numbers (10^-34) very quickly, which will get us in to trouble with computer rounding errors. When programming with likelihoods, always use logarithms !  

_insert a worked out example of using log likelihood_  















